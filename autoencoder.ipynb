{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib as plt\n",
    "from matplotlib import pyplot as plty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, TensorFlow!'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "sess = tf.Session()\n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cifar = unpickle('C:/Users/Hem/programming_/DL_projects/cifar-100-python.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = 0.70\n",
    "test = 0.3\n",
    "(trX, trY) = mnist.train.next_batch(60000)\n",
    "(valX, valY) = mnist.test.next_batch(60000)\n",
    "np.shape(trX)\n",
    "#trX, valX = np.split(trX, 50000)#[int(np.shape(trX)[0]*train)]\n",
    "#trY, valY = np.split(trY, 50000)#[int(np.shape(trY)[0]*train)]\n",
    "\n",
    "#mean = np.mean(trX,axis=0)\n",
    "#std = np.std(trX,axis=0)\n",
    "#trX = (trX - mean) / "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_pass(inp, w, b):\n",
    "    activations = [inp]\n",
    "    activation = inp\n",
    "    for i in range(num_layers):\n",
    "        activation = tf.nn.relu(tf.matmul(activation, w[0][i])+b[0][i])\n",
    "        activations.append(activation)\n",
    "    return (activations[:-1])\n",
    "        \n",
    "    return (activations[:-1], output)\n",
    "def model1(inp, w, b, p_drop):\n",
    "    \n",
    "    activations = [inp]\n",
    "    output = []\n",
    "    \n",
    "    for i in range(num_layers):\n",
    "        activation = tf.nn.relu(tf.matmul(inp[i], w[0][i])+b[0][i])\n",
    "        activations.append(activation)\n",
    "        linear_comb = tf.matmul(tf.nn.dropout(activation, p_drop[i]), w[1][i])+b[1][i]\n",
    "        output.append(linear_comb)\n",
    "        \n",
    "    return (activations[:-1], output)\n",
    "\n",
    "def mse_cost(y, y_hat):\n",
    "    return tf.reduce_mean(tf.losses.mean_squared_error(labels=y,predictions=y_hat))\n",
    "        \n",
    "def init_w(input_width, layer_width):\n",
    "    w = []\n",
    "    for i in range(0,np.shape(layer_width)[0]):\n",
    "        w.append(tf.Variable(tf.random_normal((input_width[i], layer_width[i]), stddev=0.1)))\n",
    "    return w\n",
    "        \n",
    "def init_b(layer_width):\n",
    "    b = []\n",
    "    for i in range(0,np.shape(layer_width)[0]):\n",
    "        b.append(tf.Variable(tf.zeros((layer_width[i]))))\n",
    "    return b\n",
    "\n",
    "######## HYPER PARAMS #########\n",
    "\n",
    "layers_h = [100,100,100,10]\n",
    "num_layers = np.shape(layers)\n",
    "learning_rate = 0.0001\n",
    "batch_size = 500\n",
    "\n",
    "###############################\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, trX.shape[1]], name= \"X\")\n",
    "\n",
    "\n",
    "    \n",
    "W = [init_w([trX.shape[1]] + layers_h[:-1], layers_h), #0\n",
    "     init_w(list(reversed(layers_r)), layers_h),       #1\n",
    "     init_w(layers_r, layers_r[1:]),                   #2\n",
    "     init_w(list(reversed(layers_h)), layers_r)]       #3\n",
    "B = [init_b(layers_h), \n",
    "     init_b(layers_r)]\n",
    "\n",
    "nnet = model(X,W,B,P)\n",
    "cost = mse(nnet[0],nnet[1])\n",
    "\n",
    "\n",
    "    \n",
    "train_op = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "predict_first = tf.argmax(py_x[0], 1)\n",
    "predict_last = tf.argmax(py_x[-1], 1)\n",
    "data = np.append(trX,trY, axis=1)\n",
    "\n",
    "predict_log = tf.nn.softmax(py_x)\n",
    "predict_acc = tf.argmax(py_x, 1) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \t First ts accuracy: 0.122300 \t Last ts accuracy: 0.080500\n",
      "Epoch: 10 \t First ts accuracy: 0.137200 \t Last ts accuracy: 0.187400\n",
      "Epoch: 20 \t First ts accuracy: 0.164800 \t Last ts accuracy: 0.262300\n",
      "Epoch: 30 \t First ts accuracy: 0.194700 \t Last ts accuracy: 0.354500\n",
      "Epoch: 40 \t First ts accuracy: 0.219000 \t Last ts accuracy: 0.405500\n",
      "Epoch: 50 \t First ts accuracy: 0.243900 \t Last ts accuracy: 0.471900\n",
      "Epoch: 60 \t First ts accuracy: 0.267700 \t Last ts accuracy: 0.528300\n",
      "Epoch: 70 \t First ts accuracy: 0.288800 \t Last ts accuracy: 0.560000\n",
      "Epoch: 80 \t First ts accuracy: 0.302200 \t Last ts accuracy: 0.600400\n",
      "Epoch: 90 \t First ts accuracy: 0.318700 \t Last ts accuracy: 0.625600\n",
      "Epoch: 100 \t First ts accuracy: 0.338200 \t Last ts accuracy: 0.678300\n",
      "Epoch: 110 \t First ts accuracy: 0.372100 \t Last ts accuracy: 0.729400\n",
      "Epoch: 120 \t First ts accuracy: 0.384600 \t Last ts accuracy: 0.777200\n",
      "Epoch: 130 \t First ts accuracy: 0.397700 \t Last ts accuracy: 0.782400\n",
      "Epoch: 140 \t First ts accuracy: 0.407100 \t Last ts accuracy: 0.801600\n",
      "Epoch: 150 \t First ts accuracy: 0.412500 \t Last ts accuracy: 0.802600\n",
      "Epoch: 160 \t First ts accuracy: 0.417700 \t Last ts accuracy: 0.800700\n",
      "Epoch: 170 \t First ts accuracy: 0.424300 \t Last ts accuracy: 0.817900\n",
      "Epoch: 180 \t First ts accuracy: 0.427000 \t Last ts accuracy: 0.829100\n",
      "Epoch: 190 \t First ts accuracy: 0.429000 \t Last ts accuracy: 0.830600\n",
      "Epoch: 200 \t First ts accuracy: 0.429100 \t Last ts accuracy: 0.848900\n",
      "Epoch: 210 \t First ts accuracy: 0.432500 \t Last ts accuracy: 0.827300\n",
      "Epoch: 220 \t First ts accuracy: 0.436700 \t Last ts accuracy: 0.847700\n",
      "Epoch: 230 \t First ts accuracy: 0.434400 \t Last ts accuracy: 0.859500\n",
      "Epoch: 240 \t First ts accuracy: 0.435300 \t Last ts accuracy: 0.834200\n",
      "Epoch: 250 \t First ts accuracy: 0.438000 \t Last ts accuracy: 0.849100\n",
      "Epoch: 260 \t First ts accuracy: 0.438900 \t Last ts accuracy: 0.861400\n",
      "Epoch: 270 \t First ts accuracy: 0.439300 \t Last ts accuracy: 0.856100\n",
      "Epoch: 280 \t First ts accuracy: 0.437200 \t Last ts accuracy: 0.856500\n",
      "Epoch: 290 \t First ts accuracy: 0.437800 \t Last ts accuracy: 0.866800\n",
      "Epoch: 300 \t First ts accuracy: 0.439200 \t Last ts accuracy: 0.863000\n",
      "Epoch: 310 \t First ts accuracy: 0.441300 \t Last ts accuracy: 0.860500\n",
      "Epoch: 320 \t First ts accuracy: 0.441000 \t Last ts accuracy: 0.858900\n",
      "Epoch: 330 \t First ts accuracy: 0.441600 \t Last ts accuracy: 0.872400\n",
      "Epoch: 340 \t First ts accuracy: 0.442700 \t Last ts accuracy: 0.868300\n",
      "Epoch: 350 \t First ts accuracy: 0.442500 \t Last ts accuracy: 0.883300\n",
      "Epoch: 360 \t First ts accuracy: 0.443700 \t Last ts accuracy: 0.879600\n",
      "Epoch: 370 \t First ts accuracy: 0.442800 \t Last ts accuracy: 0.872500\n",
      "Epoch: 380 \t First ts accuracy: 0.443200 \t Last ts accuracy: 0.877300\n",
      "Epoch: 390 \t First ts accuracy: 0.444400 \t Last ts accuracy: 0.888900\n",
      "Epoch: 400 \t First ts accuracy: 0.445700 \t Last ts accuracy: 0.880300\n",
      "Epoch: 410 \t First ts accuracy: 0.444300 \t Last ts accuracy: 0.885100\n",
      "Epoch: 420 \t First ts accuracy: 0.444700 \t Last ts accuracy: 0.888100\n",
      "Epoch: 430 \t First ts accuracy: 0.443700 \t Last ts accuracy: 0.889300\n",
      "Epoch: 440 \t First ts accuracy: 0.442700 \t Last ts accuracy: 0.885200\n",
      "Epoch: 450 \t First ts accuracy: 0.440300 \t Last ts accuracy: 0.897100\n",
      "Epoch: 460 \t First ts accuracy: 0.439400 \t Last ts accuracy: 0.886300\n",
      "Epoch: 470 \t First ts accuracy: 0.442000 \t Last ts accuracy: 0.895800\n",
      "Epoch: 480 \t First ts accuracy: 0.442500 \t Last ts accuracy: 0.893300\n",
      "Epoch: 490 \t First ts accuracy: 0.441700 \t Last ts accuracy: 0.897700\n",
      "Epoch: 500 \t First ts accuracy: 0.440900 \t Last ts accuracy: 0.894600\n",
      "Epoch: 510 \t First ts accuracy: 0.441100 \t Last ts accuracy: 0.890700\n",
      "Epoch: 520 \t First ts accuracy: 0.441700 \t Last ts accuracy: 0.899500\n",
      "Epoch: 530 \t First ts accuracy: 0.442100 \t Last ts accuracy: 0.886300\n",
      "Epoch: 540 \t First ts accuracy: 0.441900 \t Last ts accuracy: 0.891800\n",
      "Epoch: 550 \t First ts accuracy: 0.442200 \t Last ts accuracy: 0.897700\n",
      "Epoch: 560 \t First ts accuracy: 0.439500 \t Last ts accuracy: 0.892100\n",
      "Epoch: 570 \t First ts accuracy: 0.440100 \t Last ts accuracy: 0.899200\n",
      "Epoch: 580 \t First ts accuracy: 0.443600 \t Last ts accuracy: 0.912600\n",
      "Epoch: 590 \t First ts accuracy: 0.444100 \t Last ts accuracy: 0.890000\n",
      "Epoch: 600 \t First ts accuracy: 0.444000 \t Last ts accuracy: 0.909300\n",
      "Epoch: 610 \t First ts accuracy: 0.440900 \t Last ts accuracy: 0.903700\n",
      "Epoch: 620 \t First ts accuracy: 0.441000 \t Last ts accuracy: 0.898100\n",
      "Epoch: 630 \t First ts accuracy: 0.441800 \t Last ts accuracy: 0.902700\n",
      "Epoch: 640 \t First ts accuracy: 0.436900 \t Last ts accuracy: 0.906800\n",
      "Epoch: 650 \t First ts accuracy: 0.439100 \t Last ts accuracy: 0.897600\n",
      "Epoch: 660 \t First ts accuracy: 0.437200 \t Last ts accuracy: 0.904400\n",
      "Epoch: 670 \t First ts accuracy: 0.441000 \t Last ts accuracy: 0.906400\n",
      "Epoch: 680 \t First ts accuracy: 0.434000 \t Last ts accuracy: 0.899000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-e85c0310c7ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_Y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             print('Epoch: {} \\t First ts accuracy: {:.6f} \\t Last ts accuracy: {:.6f}'.format(i, np.mean(np.argmax(valY, axis=1) ==\n",
      "\u001b[1;32mc:\\users\\axel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\axel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\axel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\axel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\axel\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "data = np.append(trX,trY, axis=1)\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    tf.global_variables_initializer().run()\n",
    "    for i in range(100000):\n",
    "        batch_index = np.random.choice(55000, batch_size)\n",
    "        batch = data[batch_index]\n",
    "        train_X, train_Y = np.split(batch,[trX.shape[1]],axis = 1)\n",
    "        sess.run(train_op, feed_dict={X: train_X[range(0,batch_size)], Y: train_Y[range(0,batch_size)]})\n",
    "        if(i % 10 == 0):\n",
    "            print('Epoch: {} \\t First ts accuracy: {:.6f} \\t Last ts accuracy: {:.6f}'.format(i, np.mean(np.argmax(valY, axis=1) ==\n",
    "                sess.run(predict_first, feed_dict={X: valX})), np.mean(np.argmax(valY, axis=1) ==\n",
    "                sess.run(predict_last, feed_dict={X: valX})))) \n",
    "\n",
    "    print('Final Accuracy: ', np.mean(np.argmax(valY, axis=1) ==\n",
    "                sess.run(predict_op, feed_dict={X: valX})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a = np.array([1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "range(0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a[b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modelx(inputs, weights, bias, timesteps):\n",
    "    num_layers = np.shape(weights[0])[0]\n",
    "    hidden_layer = [inputs]\n",
    "    output = []\n",
    "    layers = []\n",
    "    for i in range(0,num_layers):\n",
    "        linear_comb = tf.matmul(hidden_layer[i], weights[0][i])\n",
    "        activation = tf.nn.relu(linear_comb+bias[0][i])\n",
    "        hidden_layer.append(activation)\n",
    "    hidden_layer.reverse()\n",
    "    output.append(hidden_layer[0])\n",
    "    for j in range(0,timesteps):\n",
    "        recurrent_layer = []\n",
    "        linear_comb = tf.matmul(hidden_layer[0], weights[3][0])\n",
    "        activation = tf.nn.relu(linear_comb+bias[1][0])\n",
    "        recurrent_layer.append(activation)\n",
    "        for i in range(1,num_layers):\n",
    "            linear_comb_rr = tf.matmul(recurrent_layer[i-1], weights[2][i-1])\n",
    "            linear_comb_rh = tf.matmul(hidden_layer[i], weights[3][i])\n",
    "            activation = tf.nn.tanh(linear_comb_rr + linear_comb_rh + bias[1][i]) #  + skip_c[i]*(1-(i%2)), (i%2) means skip connections for every timestep divisible by two\n",
    "            recurrent_layer.append(activation)\n",
    "        hidden_layer = [inputs]\n",
    "#        skip_c = recurrent_layer\n",
    "        recurrent_layer.reverse()\n",
    "        for i in range(0,num_layers):\n",
    "            linear_comb_hh = tf.matmul(hidden_layer[i], weights[0][i])\n",
    "            linear_comb_hr = tf.matmul(recurrent_layer[i], weights[1][i])                   \n",
    "            activation = tf.nn.relu(linear_comb_hr + linear_comb_hh + bias[0][i])\n",
    "            hidden_layer.append(activation)\n",
    "        layers.append(hidden_layer)\n",
    "        recurrent_layer = []\n",
    "        hidden_layer.reverse()\n",
    "        output.append(hidden_layer[0])\n",
    "    return (output, layers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
